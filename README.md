# ğŸ“° NewsScraper Project

A Python application that scrapes news articles, processes the text, and displays word frequency analysis in a Streamlit dashboard.
This project is for learning purposes and is not complete.

## ğŸ—ï¸ Project Structure

```
NewsScraper/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ analyzer/          # Text analysis components
â”‚   â”œâ”€â”€ data/              # Data processing scripts
â”‚   â”œâ”€â”€ scraper/           # Web scraping components
â”‚   â”œâ”€â”€ ui/                # Streamlit dashboard
â”‚   â”œâ”€â”€ paths.py           # Centralized path configuration
â”‚   â””â”€â”€ main.py            # Main application entry point
â”œâ”€â”€ data/                  # Processed data files
â”‚   â”œâ”€â”€ raw/               # Raw scraped articles
â”‚   â””â”€â”€ processed/         # Analyzed word frequencies
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md              # This file
```

## âš™ï¸ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/NewsScraper.git
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Download NLTK data:
   ```python
   python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"
   ```

## ğŸš€ Usage

Run different components using these commands:

| Command | Description |
|---------|-------------|
| `python -m src.main --full` | Run full pipeline (scrape + process + display) |
| `python -m src.main --process` | Just scrape and process data |
| `python -m src.main --ui` | Just launch the dashboard |
| `python -m src.main` | Default: process data + display dashboard |

The Streamlit dashboard will open automatically in your browser at `http://localhost:8501`

## ğŸ”§ Components

1. **Scraper**: Collects news articles from Tagesschau RSS feed
2. **Processor**: Cleans and prepares the text data
3. **Analyzer**: Calculates word frequencies
4. **Dashboard**: Interactive visualization of results
